1、能够创建scrapy项目、编写个简单的蜘蛛并运行蜘蛛；
2、能够简单的使用scrapy shell 调试数据；
3、能够使用scrapy css选择器提取简单数据；
4、除了能够提取一页数据，还要能提取下一页、在下一页。

A：首先我们需要创建一个类，并继承scrapy的一个子类：scrapy.Spider  或者是其他蜘蛛类型，后面会说到，除了Spider还有很多牛X的蜘蛛类型；
B：然后定义一个蜘蛛名，name=“”  后面我们运行的话需要用到；
C：定义我们需要爬取的网址，没有网址蜘蛛肿么爬，所以这是必须滴；
D：继承scrapy的一个方法：start_requests(self)，这个方法的作用就是通过上面定义的链接去爬取页面，简单理解就是下载页面。
那我们怎么提取我们想要的数据呢？比如我想要一个文章的标题、内容、图片，这些的话就可以我们自己定义方法提取了，后面我们慢慢涉及！这里先简单的来！
好了，我们先来看看第一个简单的蜘蛛项目：
scrapy提取数据的几种方式：CSS、XPATH、RE（正则），
scrapy shell http://lab.scrapyd.cn
response.css('title::text').extract_first()


